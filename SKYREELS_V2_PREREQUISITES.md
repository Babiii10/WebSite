# Pr√©requis pour SkyReels-V2 Text-to-Video

## Guide Complet d'Installation et Configuration

---

## üìã TABLE DES MATI√àRES

1. [Pr√©requis Mat√©riels (CRITIQUE)](#1-pr√©requis-mat√©riels-critique)
2. [Pr√©requis Logiciels](#2-pr√©requis-logiciels)
3. [Installation √âtape par √âtape](#3-installation-√©tape-par-√©tape)
4. [Configuration Syst√®me](#4-configuration-syst√®me)
5. [R√©solution de Probl√®mes](#5-r√©solution-de-probl√®mes)
6. [Optimisations et Recommandations](#6-optimisations-et-recommandations)

---

## 1. PR√âREQUIS MAT√âRIELS (CRITIQUE)

### 1.1 GPU NVIDIA avec Support CUDA

**OBLIGATOIRE:** GPU NVIDIA avec architecture r√©cente

| Sp√©cification | Minimum | Recommand√© | Optimal |
|---------------|---------|------------|---------|
| **VRAM GPU** | 24 GB | 40 GB | 80 GB |
| **Architecture** | Ampere (RTX 30xx) | Ada Lovelace (RTX 40xx) | H100/A100 |
| **Compute Capability** | 8.0+ | 8.6+ | 9.0+ |
| **Support bfloat16** | ‚úÖ Obligatoire | ‚úÖ Obligatoire | ‚úÖ Obligatoire |

#### Pourquoi ces exigences ?

Le mod√®le **SkyReels-V2-DF-14B** contient **14 milliards de param√®tres** :
- En `bfloat16` (2 bytes/param) : ~28 GB
- En `float32` (VAE, 4 bytes/param) : + 4-8 GB
- Activations et buffers interm√©diaires : + 8-15 GB
- **Total estim√© : 40-50 GB VRAM**

#### GPUs Compatibles

‚úÖ **Recommand√©:**
- NVIDIA A100 (40GB ou 80GB)
- NVIDIA H100 (80GB)
- NVIDIA A6000 (48GB)
- NVIDIA RTX 6000 Ada (48GB)

üü° **Possible avec optimisations:**
- NVIDIA RTX 4090 (24GB) - N√©cessite CPU offloading
- NVIDIA RTX 3090 (24GB) - Tr√®s lent, offloading massif
- NVIDIA A40 (48GB)

üî¥ **NON Compatible:**
- RTX 3080/3070/3060 (VRAM insuffisante)
- GTX s√©rie 10xx/20xx (pas de bfloat16)
- AMD GPUs (pas de support CUDA)
- Intel GPUs (pas de support CUDA)

### 1.2 RAM Syst√®me

| Configuration | RAM Requise | Raison |
|---------------|-------------|--------|
| **Minimum** | 64 GB | Chargement mod√®le + offloading partiel |
| **Recommand√©** | 128 GB | Offloading GPU ‚Üî CPU confortable |
| **Optimal** | 256 GB | G√©n√©ration de vid√©os longues |

### 1.3 Stockage

| Type | Capacit√© | Usage |
|------|----------|-------|
| **Mod√®le t√©l√©charg√©** | ~50-60 GB | Poids du mod√®le 14B |
| **Cache Hugging Face** | + 10 GB | Cache temporaire |
| **Vid√©os g√©n√©r√©es** | Variable | D√©pend de vos g√©n√©rations |
| **TOTAL RECOMMAND√â** | 100+ GB SSD | NVMe pour meilleures performances |

### 1.4 CPU

| Sp√©cification | Minimum | Recommand√© |
|---------------|---------|------------|
| **C≈ìurs** | 8 cores | 16+ cores |
| **Architecture** | x86_64 | x86_64 avec AVX2 |
| **Fr√©quence** | 2.5 GHz | 3.5+ GHz |

**Note:** Le CPU est utilis√© pour l'offloading m√©moire si VRAM insuffisante.

---

## 2. PR√âREQUIS LOGICIELS

### 2.1 Syst√®me d'Exploitation

‚úÖ **Support√©:**
- **Linux** (Ubuntu 20.04+, Debian 11+, CentOS 8+, Arch Linux)
- **Windows 10/11** avec WSL2 (recommand√©) ou natif
- **Windows Server 2019/2022**

üü° **Partiellement support√©:**
- macOS (pas de CUDA, n√©cessite alternatives - non recommand√©)

### 2.2 CUDA Toolkit

**CRITIQUE:** Version CUDA compatible

| Composant | Version Minimum | Version Recommand√©e |
|-----------|-----------------|---------------------|
| **CUDA Toolkit** | 11.8 | 12.1+ |
| **cuDNN** | 8.6 | 8.9+ |
| **Driver NVIDIA** | 520.xx | 535.xx+ |

#### Installation CUDA (Linux)

```bash
# Ubuntu/Debian
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
```

#### V√©rification CUDA

```bash
nvidia-smi
nvcc --version
```

### 2.3 Python

| Sp√©cification | Version |
|---------------|---------|
| **Python** | 3.9, 3.10, ou 3.11 |
| **pip** | 23.0+ |
| **virtualenv/conda** | Recommand√© |

‚ö†Ô∏è **ATTENTION:** Python 3.12+ peut avoir des incompatibilit√©s avec certaines d√©pendances.

---

## 3. INSTALLATION √âTAPE PAR √âTAPE

### √âtape 1: Cr√©er un Environnement Virtuel

#### Option A: Conda (Recommand√©)

```bash
# Installer Miniconda si n√©cessaire
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# Cr√©er environnement
conda create -n skyreels python=3.10 -y
conda activate skyreels
```

#### Option B: venv

```bash
python3.10 -m venv skyreels_env
source skyreels_env/bin/activate  # Linux/macOS
# ou
skyreels_env\Scripts\activate  # Windows
```

### √âtape 2: Installer PyTorch avec Support CUDA

**CRUCIAL:** Installer PyTorch AVANT les autres d√©pendances

```bash
# PyTorch 2.1+ avec CUDA 12.1
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121

# V√©rifier l'installation
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
```

**Sortie attendue:**
```
PyTorch: 2.1.2+cu121
CUDA available: True
CUDA version: 12.1
GPU: NVIDIA A100-SXM4-80GB  # (votre GPU)
```

### √âtape 3: Installer Diffusers et D√©pendances

```bash
# Installer diffusers depuis source (derni√®re version pour SkyReels-V2)
pip install git+https://github.com/huggingface/diffusers.git

# Ou version stable (v√©rifier compatibilit√©)
pip install diffusers>=0.30.0

# D√©pendances essentielles
pip install transformers>=4.36.0
pip install accelerate>=0.25.0
pip install safetensors>=0.4.0
pip install huggingface-hub>=0.20.0

# D√©pendances optionnelles mais recommand√©es
pip install xformers>=0.0.23  # Optimisation m√©moire CRUCIAL
pip install peft>=0.7.0  # Pour fine-tuning si n√©cessaire
pip install einops>=0.7.0  # Op√©rations tenseurs
```

### √âtape 4: Installer D√©pendances pour Export Vid√©o

```bash
# OpenCV pour traitement vid√©o
pip install opencv-python>=4.8.0
pip install opencv-contrib-python>=4.8.0

# Pillow pour images
pip install Pillow>=10.0.0

# NumPy (v√©rifier compatibilit√©)
pip install numpy>=1.24.0,<2.0.0

# Imageio pour export vid√©o
pip install imageio>=2.31.0
pip install imageio-ffmpeg>=0.4.9
```

### √âtape 5: Installer FFmpeg (Syst√®me)

#### Linux (Ubuntu/Debian)
```bash
sudo apt update
sudo apt install ffmpeg -y
ffmpeg -version
```

#### Windows
```bash
# T√©l√©charger depuis https://ffmpeg.org/download.html
# Ou via Chocolatey
choco install ffmpeg
```

#### macOS
```bash
brew install ffmpeg
```

### √âtape 6: Configurer Hugging Face Hub

```bash
# Installer CLI Hugging Face
pip install huggingface_hub[cli]

# Authentification (optionnel mais recommand√©)
huggingface-cli login
# Coller votre token depuis https://huggingface.co/settings/tokens
```

### √âtape 7: V√©rifier Installation Compl√®te

Cr√©er `test_installation.py` :

```python
import torch
import diffusers
from diffusers.utils import is_xformers_available

print("=" * 60)
print("V√âRIFICATION INSTALLATION SKYREELS-V2")
print("=" * 60)

# PyTorch
print(f"\n‚úÖ PyTorch: {torch.__version__}")
print(f"‚úÖ CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"‚úÖ Version CUDA: {torch.version.cuda}")
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"‚úÖ VRAM totale: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

    # Test bfloat16
    try:
        test_tensor = torch.zeros(1, dtype=torch.bfloat16, device="cuda")
        print(f"‚úÖ Support bfloat16: OUI")
    except:
        print(f"‚ùå Support bfloat16: NON (GPU incompatible)")
else:
    print("‚ùå CUDA NON disponible - V√©rifiez votre installation")

# Diffusers
print(f"\n‚úÖ Diffusers: {diffusers.__version__}")

# XFormers
if is_xformers_available():
    print(f"‚úÖ XFormers: Disponible (optimisation m√©moire activ√©e)")
else:
    print(f"‚ö†Ô∏è XFormers: Non disponible (performances r√©duites)")

# RAM
import psutil
ram_total = psutil.virtual_memory().total / 1024**3
print(f"\n‚úÖ RAM syst√®me: {ram_total:.2f} GB")

# Espace disque
import shutil
disk = shutil.disk_usage("/")
disk_free = disk.free / 1024**3
print(f"‚úÖ Espace disque libre: {disk_free:.2f} GB")

print("\n" + "=" * 60)
if torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory / 1024**3 >= 24:
    print("‚úÖ SYST√àME COMPATIBLE AVEC SKYREELS-V2")
else:
    print("‚ö†Ô∏è VRAM INSUFFISANTE - 24 GB minimum requis")
print("=" * 60)
```

Ex√©cuter :
```bash
python test_installation.py
```

---

## 4. CONFIGURATION SYST√àME

### 4.1 Variables d'Environnement

Ajouter dans `~/.bashrc` ou `~/.zshrc` :

```bash
# CUDA
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# Hugging Face Cache (optionnel, pour changer r√©pertoire cache)
export HF_HOME=/path/to/large/disk/huggingface_cache
export TRANSFORMERS_CACHE=$HF_HOME/transformers
export HF_DATASETS_CACHE=$HF_HOME/datasets

# PyTorch optimisations
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Pour debugging
# export CUDA_LAUNCH_BLOCKING=1
```

Recharger :
```bash
source ~/.bashrc
```

### 4.2 Optimisations M√©moire

Cr√©er fichier `skyreels_config.py` :

```python
import torch
import gc

def setup_memory_optimization():
    """Configure optimisations m√©moire pour SkyReels-V2"""

    # Vider cache CUDA
    torch.cuda.empty_cache()
    gc.collect()

    # Configuration PyTorch
    torch.backends.cuda.matmul.allow_tf32 = True  # Acc√©l√©ration matmul
    torch.backends.cudnn.allow_tf32 = True
    torch.backends.cudnn.benchmark = True  # Auto-optimisation cuDNN

    # Allocation m√©moire graduelle
    torch.cuda.set_per_process_memory_fraction(0.95)  # Utiliser 95% VRAM max

    print("‚úÖ Optimisations m√©moire activ√©es")

def print_memory_stats():
    """Affiche statistiques m√©moire GPU"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated(0) / 1024**3
        reserved = torch.cuda.memory_reserved(0) / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3

        print(f"\nüìä M√©moire GPU:")
        print(f"  Allou√©e: {allocated:.2f} GB")
        print(f"  R√©serv√©e: {reserved:.2f} GB")
        print(f"  Totale: {total:.2f} GB")
        print(f"  Libre: {total - reserved:.2f} GB")
```

### 4.3 Script de G√©n√©ration Complet

Cr√©er `generate_video.py` :

```python
import torch
from diffusers import AutoModel, SkyReelsV2DiffusionForcingPipeline, UniPCMultistepScheduler
from diffusers.utils import export_to_video
import gc
from skyreels_config import setup_memory_optimization, print_memory_stats

# Configuration m√©moire
setup_memory_optimization()

print("üì• Chargement du mod√®le SkyReels-V2...")
print("‚è≥ Ceci peut prendre 5-10 minutes selon votre connexion internet...")

# Charger VAE en float32 (meilleure qualit√©)
vae = AutoModel.from_pretrained(
    "Skywork/SkyReels-V2-DF-14B-540P-Diffusers",
    subfolder="vae",
    torch_dtype=torch.float32
)

# Charger pipeline principal en bfloat16 (√©conomie m√©moire)
pipeline = SkyReelsV2DiffusionForcingPipeline.from_pretrained(
    "Skywork/SkyReels-V2-DF-14B-540P-Diffusers",
    vae=vae,
    torch_dtype=torch.bfloat16
)

# Configuration scheduler
flow_shift = 8.0  # 8.0 pour Text-to-Video, 5.0 pour Image-to-Video
pipeline.scheduler = UniPCMultistepScheduler.from_config(
    pipeline.scheduler.config,
    flow_shift=flow_shift
)

# Optimisation XFormers (si disponible)
try:
    pipeline.enable_xformers_memory_efficient_attention()
    print("‚úÖ XFormers activ√©")
except:
    print("‚ö†Ô∏è XFormers non disponible")

# D√©placer vers GPU
pipeline = pipeline.to("cuda")

print_memory_stats()
print("\n‚úÖ Mod√®le charg√© avec succ√®s!")

# Prompt
prompt = """A cat and a dog baking a cake together in a kitchen.
The cat is carefully measuring flour, while the dog is stirring the batter
with a wooden spoon. The kitchen is cozy, with sunlight streaming through
the window."""

print(f"\nüé¨ G√©n√©ration vid√©o...")
print(f"Prompt: {prompt}")

# G√©n√©ration
output = pipeline(
    prompt=prompt,
    num_inference_steps=30,      # Plus = meilleure qualit√© mais plus lent
    height=544,                  # 720 pour 720P
    width=960,                   # 1280 pour 720P
    num_frames=97,               # Nombre de frames (97 = ~4 secondes √† 24fps)
    base_num_frames=97,          # 121 pour 720P
    ar_step=5,                   # Contr√¥le inf√©rence asynchrone (0 pour mode synchrone)
    causal_block_size=5,         # Frames par block pour traitement asynchrone
    overlap_history=None,        # 17 pour vid√©os longues
    addnoise_condition=20,       # Am√©liore coh√©rence pour vid√©os longues
    generator=torch.Generator(device="cuda").manual_seed(42)  # Pour reproductibilit√©
).frames[0]

# Export
output_path = "output_T2V.mp4"
export_to_video(output, output_path, fps=24, quality=8)

print(f"\n‚úÖ Vid√©o g√©n√©r√©e: {output_path}")
print_memory_stats()

# Nettoyage m√©moire
del pipeline
del vae
torch.cuda.empty_cache()
gc.collect()
```

---

## 5. R√âSOLUTION DE PROBL√àMES

### Probl√®me 1: CUDA Out of Memory (OOM)

**Erreur:**
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB
```

**Solutions:**

#### A. R√©duire la r√©solution
```python
height=416,  # Au lieu de 544
width=736,   # Au lieu de 960
```

#### B. R√©duire le nombre de frames
```python
num_frames=49,  # Au lieu de 97
base_num_frames=49,
```

#### C. Activer CPU Offloading
```python
# AVANT pipeline.to("cuda")
pipeline.enable_model_cpu_offload()  # Offload automatique
# OU
pipeline.enable_sequential_cpu_offload()  # Plus agressif
```

#### D. R√©duire pr√©cision VAE
```python
# Charger VAE en bfloat16 au lieu de float32
vae = AutoModel.from_pretrained(
    "Skywork/SkyReels-V2-DF-14B-540P-Diffusers",
    subfolder="vae",
    torch_dtype=torch.bfloat16  # Attention: qualit√© l√©g√®rement r√©duite
)
```

#### E. Activer attention slicing
```python
pipeline.enable_attention_slicing(slice_size=1)
```

### Probl√®me 2: Import Error - Module Not Found

**Erreur:**
```
ModuleNotFoundError: No module named 'diffusers.pipelines.skyreels'
```

**Solution:**
```bash
# Installer version d√©veloppement
pip uninstall diffusers -y
pip install git+https://github.com/huggingface/diffusers.git
```

### Probl√®me 3: T√©l√©chargement √âchoue

**Erreur:**
```
HTTPError: 403 Forbidden
```

**Solution:**
```bash
# Authentifier avec Hugging Face
huggingface-cli login

# Ou dans le code
from huggingface_hub import login
login(token="YOUR_HF_TOKEN")
```

### Probl√®me 4: bfloat16 Non Support√©

**Erreur:**
```
RuntimeError: "addmm_impl_cpu_" not implemented for 'BFloat16'
```

**Solution:**
```python
# Votre GPU ne supporte pas bfloat16, utiliser float16
pipeline = SkyReelsV2DiffusionForcingPipeline.from_pretrained(
    "Skywork/SkyReels-V2-DF-14B-540P-Diffusers",
    vae=vae,
    torch_dtype=torch.float16  # Au lieu de bfloat16
)
```

### Probl√®me 5: G√©n√©ration Trop Lente

**Solutions:**

1. **R√©duire num_inference_steps:**
```python
num_inference_steps=20,  # Au lieu de 30 (qualit√© l√©g√®rement r√©duite)
```

2. **Activer compilation PyTorch 2.0:**
```python
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```

3. **Utiliser GPU plus puissant ou cloud:**
- AWS EC2 P4d (A100)
- Google Colab Pro+ (A100)
- RunPod / Vast.ai

---

## 6. OPTIMISATIONS ET RECOMMANDATIONS

### 6.1 Param√®tres de G√©n√©ration

| Param√®tre | Valeur Rapide | Valeur √âquilibr√©e | Valeur Qualit√© |
|-----------|---------------|-------------------|----------------|
| `num_inference_steps` | 15 | 30 | 50 |
| `height x width` | 416x736 | 544x960 | 720x1280 |
| `num_frames` | 49 | 97 | 121 |
| `quality` (export) | 6 | 8 | 10 |

### 6.2 Temps de G√©n√©ration Estim√©s

| GPU | R√©solution | Frames | Steps | Temps Estim√© |
|-----|------------|--------|-------|--------------|
| RTX 4090 (24GB) + offload | 544x960 | 97 | 30 | ~15-20 min |
| A100 40GB | 544x960 | 97 | 30 | ~8-12 min |
| A100 80GB | 720x1280 | 121 | 30 | ~12-18 min |
| H100 80GB | 720x1280 | 121 | 50 | ~15-20 min |

### 6.3 Meilleures Pratiques pour Prompts

```python
# ‚úÖ BON: Descriptif, d√©taill√©, coh√©rent
prompt = """A fluffy orange cat wearing a tiny chef's hat, standing on its
hind legs at a kitchen counter. The cat is carefully pouring flour from a bag
into a large mixing bowl. Next to it, a golden retriever with a red bandana
is stirring cake batter with a wooden spoon, its tail wagging. The kitchen
has warm wooden cabinets, white marble countertops, and bright morning sunlight
streaming through a window with white curtains. On the counter: eggs, butter,
and a recipe book."""

# ‚ùå MAUVAIS: Vague, court
prompt = "Cat and dog cooking"
```

### 6.4 Utilisation en Production

#### A. Syst√®me de Queue

```python
from queue import Queue
import threading

video_queue = Queue()

def process_video_requests():
    while True:
        prompt = video_queue.get()
        if prompt is None:
            break

        # G√©n√©rer vid√©o
        output = pipeline(prompt=prompt, ...)
        export_to_video(output, f"video_{hash(prompt)}.mp4")

        video_queue.task_done()

# D√©marrer worker
worker = threading.Thread(target=process_video_requests)
worker.start()

# Ajouter requ√™tes
video_queue.put("A cat playing piano")
video_queue.put("A dog surfing")
```

#### B. API REST avec FastAPI

```python
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel

app = FastAPI()

class VideoRequest(BaseModel):
    prompt: str
    num_frames: int = 97
    num_inference_steps: int = 30

@app.post("/generate")
async def generate_video(request: VideoRequest, background_tasks: BackgroundTasks):
    # G√©n√©rer en arri√®re-plan
    background_tasks.add_task(generate_and_save, request.prompt, request.num_frames)
    return {"status": "processing", "prompt": request.prompt}

def generate_and_save(prompt: str, num_frames: int):
    output = pipeline(prompt=prompt, num_frames=num_frames, ...)
    export_to_video(output, f"videos/{hash(prompt)}.mp4")
```

---

## 7. CHECKLIST FINALE

### Avant de D√©marrer

- [ ] GPU NVIDIA avec 24+ GB VRAM
- [ ] Driver NVIDIA 520+
- [ ] CUDA Toolkit 11.8+
- [ ] Python 3.9/3.10/3.11
- [ ] 64+ GB RAM syst√®me
- [ ] 100+ GB espace disque libre (SSD)
- [ ] PyTorch 2.0+ avec CUDA install√©
- [ ] Diffusers 0.30+ install√©
- [ ] XFormers install√© (optionnel mais recommand√©)
- [ ] FFmpeg install√©
- [ ] Compte Hugging Face (optionnel)

### Test Rapide

```bash
# Activer environnement
conda activate skyreels

# Test installation
python test_installation.py

# G√©n√©ration test (petite r√©solution)
python -c "
import torch
from diffusers import AutoModel, SkyReelsV2DiffusionForcingPipeline
vae = AutoModel.from_pretrained('Skywork/SkyReels-V2-DF-14B-540P-Diffusers', subfolder='vae', torch_dtype=torch.float32)
pipeline = SkyReelsV2DiffusionForcingPipeline.from_pretrained('Skywork/SkyReels-V2-DF-14B-540P-Diffusers', vae=vae, torch_dtype=torch.bfloat16)
pipeline = pipeline.to('cuda')
print('‚úÖ Mod√®le charg√© avec succ√®s!')
"
```

---

## 8. RESSOURCES ET SUPPORT

### Documentation Officielle
- GitHub: https://github.com/SkyworkAI/SkyReels-V2
- Hugging Face: https://huggingface.co/Skywork/SkyReels-V2-DF-14B-540P-Diffusers
- Diffusers Docs: https://huggingface.co/docs/diffusers

### Communaut√©
- Hugging Face Forums: https://discuss.huggingface.co/
- Discord Diffusers: https://discord.gg/hugging-face

### Cloud GPU Providers (Si pas de GPU local)
- Google Colab Pro+ (A100): $50/mois
- RunPod.io: ~$1.50-2.50/heure (A100)
- Vast.ai: ~$0.70-1.50/heure (A100)
- Lambda Labs: ~$1.10/heure (A100)
- AWS EC2 P4d: ~$32/heure (A100)

---

## R√âSUM√â EX√âCUTIF

**Pr√©requis MINIMUMS pour SkyReels-V2:**

1. ‚úÖ GPU NVIDIA avec 24+ GB VRAM (40+ GB recommand√©)
2. ‚úÖ Support bfloat16 (architecture Ampere ou plus r√©cente)
3. ‚úÖ CUDA 11.8+ avec drivers 520+
4. ‚úÖ Python 3.9-3.11
5. ‚úÖ PyTorch 2.0+ avec CUDA
6. ‚úÖ Diffusers 0.30+
7. ‚úÖ 64+ GB RAM syst√®me
8. ‚úÖ 100+ GB stockage SSD
9. ‚úÖ FFmpeg install√©
10. ‚úÖ ~10-20 minutes de temps de g√©n√©ration par vid√©o

**Co√ªt estim√© si pas de mat√©riel:**
- Cloud GPU: $1-3/heure
- G√©n√©ration vid√©o: ~15 minutes = $0.25-0.75 par vid√©o

---

*Document cr√©√© le 2025-10-22*
*Pour support: Consulter documentation officielle SkyworkAI*
